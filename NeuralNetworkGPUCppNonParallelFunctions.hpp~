//Private member functions (keep this comment - it is necessary for the automatic generation of the script)

//Protected member functions (keep this comment - it is necessary for the automatic generation of the script)

//Public member functions (keep this comment - it is necessary for the automatic generation of the script)

NeuralNetworkGPUCpp::NeuralNetworkGPUCpp(std::int32_t *_num_input_nodes_dense, std::int32_t _num_input_nodes_dense_length, std::int32_t *_num_input_nodes_sparse, std::int32_t _num_input_nodes_sparse_length, std::int32_t _num_output_nodes_dense, std::int32_t _num_output_nodes_sparse, LossFunctionCpp *loss/*, RegulariserCpp *regulariser*/) {

  //Make that the input is reasonable
  if (_num_input_nodes_dense_length + _num_input_nodes_sparse_length <= 0) throw std::invalid_argument("You must provide at least some input nodes!");
  if (_num_output_nodes_dense + _num_output_nodes_sparse <= 0) throw std::invalid_argument("You must provide at least some output nodes!");

  if (std::any_of(_num_input_nodes_dense, _num_input_nodes_dense + _num_input_nodes_dense_length, [](int i){return i <= 0;})) throw std::invalid_argument("Width of all input matrices must be greater than 0!");
  if (std::any_of(_num_input_nodes_sparse, _num_input_nodes_sparse + _num_input_nodes_sparse_length, [](int i){return i <= 0;})) throw std::invalid_argument("Width of all input matrices must be greater than 0!");

  //Init num_hidden_nodes
  this->num_hidden_nodes = (std::size_t)0;
  
  //Init num_output_nodes
  this->num_output_nodes_dense = _num_output_nodes_dense; 
  this->num_output_nodes_sparse = _num_output_nodes_sparse;
  this->num_output_nodes = _num_output_nodes_dense + _num_output_nodes_sparse;

  //Set up input data and target data
  this->dense_input_data = std::vector<DenseInputStruct>(_num_input_nodes_dense_length);
  this->sparse_input_data = std::vector<SparseInputStruct>(_num_input_nodes_sparse_length);
  this->dense_targets = std::vector<DenseInputStruct>(_num_output_nodes_dense);
  this->sparse_targets = std::vector<SparseInputStruct>(_num_output_nodes_sparse);

  //Transfer number of input nodes
  for (int i=0; i <_num_input_nodes_dense_length; ++i) this->dense_input_data[i].dim = _num_input_nodes_dense[i];
  for (int i=0; i <_num_input_nodes_sparse_length; ++i) this->sparse_input_data[i].dim = _num_input_nodes_sparse[i];
  
  this->loss = loss;
  //this->regulariser = regulariser;
		
  this->nodes = std::vector<NeuralNetworkNodeGPUCpp*>(this->num_output_nodes);		
  this->output_nodes = nodes.data();

  //Initialise to nullptr\
  std::fill(this->nodes.begin(), this->nodes.end(), nullptr);
				
  //Since neural network has not been finalised, set finalised to false
  this->finalised = false;

}
					 
NeuralNetworkGPUCpp::~NeuralNetworkGPUCpp()  {};

void NeuralNetworkGPUCpp::init_hidden_node(NeuralNetworkNodeGPUCpp *_hidden_node) {
	
  //Make sure that the neural network has not already been finalised!
  if (this->finalised) throw std::invalid_argument("Neural network has already been finalised!");

  if (_hidden_node->node_number >= this->num_hidden_nodes) {	

    std::int32_t NumAdditionalNodes = _hidden_node->node_number + 1 - this->num_hidden_nodes;

    //Extend hidden nodes vector
    std::vector<NeuralNetworkNodeGPUCpp*>::iterator it = this->nodes.begin() + this->nodes.size();
    this->nodes.insert(it, NumAdditionalNodes, nullptr);	

    //Increase num_hidden_nodes and reset pointer output_nodes
    this->num_hidden_nodes += NumAdditionalNodes;
    this->output_nodes = nodes.data() + this->num_hidden_nodes;

    //Increase node_number of output_nodes
    for (std::int32_t i=0; i<this->num_output_nodes; ++i) if (this->output_nodes[i] != nullptr) this->output_nodes[i]->node_number += NumAdditionalNodes;
  }

  this->nodes[_hidden_node->node_number] = _hidden_node;
					
};

void NeuralNetworkGPUCpp::init_output_node(NeuralNetworkNodeGPUCpp *_output_node) {
		
  //Make sure that the neural network has not already been finalised!
  if (this->finalised) 
    throw std::invalid_argument("Neural network has already been finalised!");
  
  //Make sure that node number is in range
  if (_output_node->node_number >= (std::int32_t)(this->nodes.size()) || _output_node->node_number < 0) 
    throw std::invalid_argument("Output node: Node number out of range!");
				
  this->nodes[_output_node->node_number] = _output_node;
						
};

void NeuralNetworkGPUCpp::finalise(/*MPI_Comm comm, std::int32_t rank, std::int32_t size,*/float _weight_init_range) {

  //Make sure that neural net has not been finalised already
  if (this->finalised == true)
    throw std::invalid_argument("Neural network has already been finalised!");

  //Make sure that all nodes were initialised
  if (std::any_of(this->nodes.begin(), this->nodes.end(), [](NeuralNetworkNodeGPUCpp *node) {return node == nullptr;}))
      throw std::invalid_argument("Not all nodes have been initialised!");
    
  //Calculate pointer to hidden nodes fed into me
  for (auto node: this->nodes) {

    node->hidden_nodes_fed_into_me_ptr.clear();
    for (auto i: node->hidden_nodes_fed_into_me) node->hidden_nodes_fed_into_me_ptr.push_back(this->nodes[i]);

  }
   
  //Transfer number fo input nodes to nodes, so we can calculate the number of weights needed
  for (auto node: this->nodes) {

    //Set initial value to zero
    node->num_input_nodes_cumulative = 0;

    //Add dense input
    for (auto dense: node->input_nodes_fed_into_me_dense) node->num_input_nodes_cumulative += this->dense_input_data[dense].dim;

    //Add sparse input
    for (auto sparse: node->input_nodes_fed_into_me_sparse) node->num_input_nodes_cumulative += this->sparse_input_data[sparse].dim;
     
  }

  //Transfer number of output nodes to targets
  for (int i=0; i < this->num_output_nodes_dense; ++i) dense_targets[i].dim = 1;//Temporary solution until layers are implemented! 
  for (int i=0; i < this->num_output_nodes_sparse; ++i) sparse_targets[i].dim = 1;//Temporary solution until layers are implemented! 

  //Calculate cumulative_num_weights_required and initialise W
  std::int32_t lengthW = 0;
  std::vector<std::int32_t> cumulative_num_weights_requiredHost;
  for (auto node: this->nodes) {

    node->NeuralNet = this;
    cumulative_num_weights_requiredHost.push_back(lengthW);
    lengthW += node->get_num_weights_required();

  }

  cumulative_num_weights_requiredHost.push_back(lengthW);

  //Transfer cumulative_num_weights_required to device vector
  this->cumulative_num_weights_required = thrust::device_vector<std::int32_t>(cumulative_num_weights_requiredHost.data(), cumulative_num_weights_requiredHost.data() + cumulative_num_weights_requiredHost.size());

  //Init Whost
  std::vector<float> Whost(lengthW);
  
  std::mt19937 gen(1);//Note that we deliberately choose a constant seed to get the same output every time we call the function
  std::uniform_real_distribution<float> dist(_weight_init_range*(-1.0f), _weight_init_range);

  //Initialise weight vector
  //The vector of weights associated with the input nodes cannot be a csr_matrix. The solution is to keep a set of weights that always assume the value of 0.0.
  for (auto node: this->nodes) {
         
    for (std::int32_t i = cumulative_num_weights_requiredHost[node->node_number]; i < cumulative_num_weights_requiredHost[node->node_number + 1]; ++i) Whost[i] = dist(gen);
            
  }
  
  //Transfor to device vector
  this->W = thrust::device_vector<float>(Whost.data(), Whost.data() + Whost.size());

  //Set finalised to true so we know we can now fit the neural network
  this->finalised = true;
  
}

std::int32_t NeuralNetworkGPUCpp::get_length_params() {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");

  return (std::int32_t)(this->W.size());
		
};

void NeuralNetworkGPUCpp::get_params(float *_W, std::int32_t _length_W) {

  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  
  for (std::int32_t i=0; i<_length_W; ++i) _W[i] = this->W[i];

}

std::int32_t NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_dense_length(std::int32_t _node_number) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_node_number < 0 || _node_number >= (std::int32_t)(nodes.size())) std::invalid_argument("node_number out of bounds!");

  return (std::int32_t)(this->nodes[_node_number]->input_nodes_fed_into_me_dense.size());
		
};

void NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_dense(std::int32_t _node_number, std::int32_t *_input_nodes_fed_into_me_dense, std::int32_t _input_nodes_fed_into_me_dense_length) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_node_number < 0 || _node_number >= (std::int32_t)(nodes.size())) std::invalid_argument("node_number out of bounds!");
		
  for (std::int32_t i=0; i<_input_nodes_fed_into_me_dense_length; ++i) _input_nodes_fed_into_me_dense[i] = this->nodes[_node_number]->input_nodes_fed_into_me_dense[i];
  		
};

std::int32_t NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_sparse_length(std::int32_t _node_number) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_node_number < 0 || _node_number >= (std::int32_t)(nodes.size())) std::invalid_argument("node_number out of bounds!");

  return (std::int32_t)(this->nodes[_node_number]->input_nodes_fed_into_me_sparse.size());
		
};

void NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_sparse(std::int32_t _node_number, std::int32_t *_input_nodes_fed_into_me_sparse, std::int32_t _input_nodes_fed_into_me_sparse_length) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_node_number < 0 || _node_number >= (std::int32_t)(nodes.size())) std::invalid_argument("node_number out of bounds!");
		
  for (std::int32_t i=0; i<_input_nodes_fed_into_me_sparse_length; ++i) _input_nodes_fed_into_me_sparse[i] = this->nodes[_node_number]->input_nodes_fed_into_me_sparse[i];
  		
};
     
std::int32_t NeuralNetworkGPUCpp::get_hidden_nodes_fed_into_me_length(std::int32_t _node_number) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_node_number < 0 || _node_number >= (std::int32_t)(nodes.size())) std::invalid_argument("node_number out of bounds!");

  return (std::int32_t)(this->nodes[_node_number]->hidden_nodes_fed_into_me.size());
		
};

void NeuralNetworkGPUCpp::get_hidden_nodes_fed_into_me(std::int32_t _node_number, std::int32_t *_hidden_nodes_fed_into_me, std::int32_t __lengthhidden_nodes_fed_into_me) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_node_number < 0 || _node_number >= (std::int32_t)(nodes.size())) std::invalid_argument("node_number out of bounds!");
		
  for (std::int32_t i=0; i<__lengthhidden_nodes_fed_into_me; ++i) _hidden_nodes_fed_into_me[i] = this->nodes[_node_number]->hidden_nodes_fed_into_me[i];
  		
};

void NeuralNetworkGPUCpp::load_dense(DenseInputStruct &data, float *_X, std::int32_t _num_samples, std::int32_t _dim) {

  //Transfer _num_samples and _dim
  data.I = _num_samples;
  data.dim = _dim;

  //Transfer X to GPU and set X_ptr
  data.X = thrust::device_vector<float>(_X, _X + _num_samples*_dim);
  data.X_ptr = thrust::raw_pointer_cast(data.X.data()); 

}

void NeuralNetworkGPUCpp::load_dense_data(std::int32_t _num_input_node, float *_X, std::int32_t _num_samples, std::int32_t _dim) {

  if (_num_input_node >= (std::int32_t)(this->dense_input_data.size()) || _num_input_node < 0) throw std::invalid_argument("num_input_node out of bounds!");
  if (_dim != this->dense_input_data[_num_input_node].dim) throw std::invalid_argument("Width dim of array provided does not match the width that has been set when initialising the network!");
  
  this->load_dense(this->dense_input_data[_num_input_node], _X, _num_samples, _dim);

}

void NeuralNetworkGPUCpp::load_dense_targets(std::int32_t _num_output_node, float *_Y, std::int32_t _num_samples, std::int32_t _dim) {

  if (_num_output_node >= (std::int32_t)(this->dense_targets.size()) || _num_output_node < 0) throw std::invalid_argument("num_output_node out of bounds!");
  if (_dim != this->dense_targets[_num_output_node].dim) throw std::invalid_argument("Width dim of array provided does not match the width that has been set when initialising the network!");
  
  this->load_dense(this->dense_targets[_num_output_node], _Y, _num_samples, _dim);

}

void NeuralNetworkGPUCpp::load_sparse(SparseInputStruct &data, float *_X_data, std::int32_t _X_data_length,  std::int32_t *_X_indices, std::int32_t _X_indices_length, std::int32_t *_X_indptr, std::int32_t _X_indptr_length, std::int32_t _num_samples, std::int32_t _dim) {

  //Transfer _num_samples and _dim
  data.I = _num_samples;
  data.dim = _dim;

  //Transfer X_data to GPU and set X_data_ptr  
  data.X_data = thrust::device_vector<float>(_X_data, _X_data + _X_data_length);
  data.X_data_ptr = thrust::raw_pointer_cast(data.X_data.data()); 

  //Transfer X_indices to GPU and set X_indices_ptr
  data.X_indices = thrust::device_vector<std::int32_t>(_X_indices, _X_indices + _X_indices_length);
  data.X_indices_ptr = thrust::raw_pointer_cast(data.X_indices.data()); 

  //Transfer X_indptr to GPU and set X_indptr_ptr
  data.X_indptr = thrust::device_vector<std::int32_t>(_X_indptr, _X_indptr + _X_indptr_length);
  data.X_indptr_ptr = thrust::raw_pointer_cast(data.X_indptr.data()); 

}

void NeuralNetworkGPUCpp::load_sparse_data(std::int32_t _num_input_node, float *_X_data, std::int32_t _X_data_length,  std::int32_t *_X_indices, std::int32_t _X_indices_length, std::int32_t *_X_indptr, std::int32_t _X_indptr_length, std::int32_t _num_samples, std::int32_t _dim) {

  if (_num_input_node >= (std::int32_t)(this->sparse_input_data.size()) || _num_input_node < 0) throw std::invalid_argument("num_input_node out of bounds!");
  if (_dim != this->sparse_input_data[_num_input_node].dim) throw std::invalid_argument("Width dim of array provided does not match the width that has been set when initialising the network!");

  this->load_sparse(this->sparse_input_data[_num_input_node], _X_data, _X_data_length, _X_indices, _X_indices_length, _X_indptr, _X_indptr_length, _num_samples, _dim);

}

void NeuralNetworkGPUCpp::load_sparse_targets(std::int32_t _num_output_node, float *_Y_data, std::int32_t _Y_data_length,  std::int32_t *_Y_indices, std::int32_t _Y_indices_length, std::int32_t *_Y_indptr, std::int32_t _Y_indptr_length, std::int32_t _num_samples, std::int32_t _dim) {

  if (_num_output_node >= (std::int32_t)(this->sparse_targets.size()) || _num_output_node < 0) throw std::invalid_argument("num_output_node out of bounds!");
  if (_dim != this->sparse_targets[_num_output_node].dim) throw std::invalid_argument("Width dim of array provided does not match the width that has been set when initialising the network!");

  this->load_sparse(this->sparse_targets[_num_output_node], _Y_data, _Y_data_length, _Y_indices, _Y_indices_length, _Y_indptr, _Y_indptr_length, _num_samples, _dim);

}

void NeuralNetworkGPUCpp::delete_data() {

  for (auto data: this->dense_input_data) data.X.clear();

  for (auto data: this->dense_targets) data.X.clear();

  for (auto data: this->sparse_input_data) {
    data.X_data.clear();
    data.X_indices.clear();
    data.X_indptr.clear();
  }

  for (auto data: this->sparse_targets) {
    data.X_data.clear();
    data.X_indices.clear();
    data.X_indptr.clear();
  }

}
	           
void NeuralNetworkGPUCpp::transform(float *_Yhat, std::int32_t _Y2_num_samples, std::int32_t _Y2_dim, const std::int32_t _MinibatchSizeStandard, bool _sample, std::int32_t _sample_size, bool _Gethidden_nodes) {
		
  //Make sure that neural network has been finalised!
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  
  //Make sure that _Y2_num_samples matches num_samples in input matrices
  for (auto data: this->dense_input_data) if (_Y2_num_samples != data.I) throw std::invalid_argument("All input matrices must have the exact same number of samples!");

  for (auto data: this->sparse_input_data) if (_Y2_num_samples != data.I) throw std::invalid_argument("All input matrices must have the exact same number of samples!");
  
  //Store input values
  this->num_samples = _Y2_num_samples;
  this->sample = _sample;
  if (!_sample) _sample_size = 1;

  const double SampleAvg = 1.0/((double)_sample_size);

  //this->MinibatchSizeStandard determines the number of samples that are calculated at once when calling the functions.
  //It must be optimised for cache efficiency
  this->MinibatchSizeStandard = _MinibatchSizeStandard;

  //Set pointers contained in the NeuralNetworkNodes class
  for (std::size_t n=0; n<this->nodes.size(); ++n) this->nodes[n]->W = thrust::raw_pointer_cast(this->W.data()) + this->cumulative_num_weights_required[n];
  
  //Init YhatTemp
  thrust::device_vector<float> YhatTemp(_Yhat, _Yhat + _Y2_num_samples*_Y2_dim);
  
  //Init cuBLAS handle
  cublasCreate(&(this->handle));

  //Calculate output
  std::int32_t MinibatchSize;
  for (std::int32_t MinibatchBegin=0; MinibatchBegin<this->num_samples; MinibatchBegin += this->MinibatchSizeStandard) {

    //Calculate MinibatchSize
    MinibatchSize = std::min(this->num_samples - MinibatchBegin, this->MinibatchSizeStandard);
    						
    //Calculate nodes
    for (auto node: this->nodes) node->calc_output(MinibatchBegin, MinibatchSize);

    //Add to YhatTemp
    for (std::int32_t n=0; n<this->num_output_nodes; ++n) thrust::transform(this->output_nodes[n]->output.begin(), this->output_nodes[n]->output.end(), YhatTemp.begin() + _Y2_num_samples*n + MinibatchBegin, YhatTemp.begin() + _Y2_num_samples*n + MinibatchBegin, thrust::plus<float>());

  }	
  
  //Get data from YhatTemp and transpose
  for (std::int32_t i=0; i<_Y2_num_samples; ++i) for (std::int32_t j=0; j<_Y2_dim; ++j) _Yhat[i*_Y2_dim + j] = YhatTemp[j*_Y2_num_samples + i];

  //Destroy cuBLAS handle
  cublasDestroy(this->handle);
			
  //Clear data. so it does not unnecessarily take up space on the GPU
  this->delete_data();
		
};
