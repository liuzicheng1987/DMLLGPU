//Private member functions (keep this comment - it is necessary for the automatic generation of the script)

//Protected member functions (keep this comment - it is necessary for the automatic generation of the script)

//Public member functions (keep this comment - it is necessary for the automatic generation of the script)

NeuralNetworkGPUCpp::NeuralNetworkGPUCpp(std::int32_t *_NumInputNodesDense, std::int32_t _NumInputNodesDenseLength, std::int32_t *_NumInputNodesSparse, std::int32_t _NumInputNodesSparseLength, std::int32_t _NumOutputNodesDense, std::int32_t _NumOutputNodesSparse, LossFunctionCpp *loss/*, RegulariserCpp *regulariser*/) {

  //Make that the input is reasonable
  if (_NumInputNodesDenseLength + _NumInputNodesSparseLength <= 0) throw std::invalid_argument("You must provide at least some input nodes!");
  if (_NumOutputNodesDense + _NumOutputNodesSparse <= 0) throw std::invalid_argument("You must provide at least some output nodes!");

  if (std::any_of(_NumInputNodesDense, _NumInputNodesDense + _NumInputNodesDenseLength, [](int i){return i <= 0;})) throw std::invalid_argument("Width of all input matrices must be greater than 0!");
  if (std::any_of(_NumInputNodesSparse, _NumInputNodesSparse + _NumInputNodesSparseLength, [](int i){return i <= 0;})) throw std::invalid_argument("Width of all input matrices must be greater than 0!");

  //Init NumHiddenNodes
  this->NumHiddenNodes = (std::size_t)0;
  
  //Init NumOutputNodes
  this->NumOutputNodesDense = _NumOutputNodesDense; 
  this->NumOutputNodesSparse = _NumOutputNodesSparse;
  this->NumOutputNodes = _NumOutputNodesDense + _NumOutputNodesSparse;

  //Set up input data and target data
  this->DenseInputData = std::vector<DenseInputStruct>(_NumInputNodesDenseLength);
  this->SparseInputData = std::vector<SparseInputStruct>(_NumInputNodesSparseLength);
  this->DenseTargets = std::vector<DenseInputStruct>(_NumOutputNodesDense);
  this->SparseTargets = std::vector<SparseInputStruct>(_NumOutputNodesSparse);

  //Transfer number of input nodes
  for (int i=0; i <_NumInputNodesDenseLength; ++i) this->DenseInputData[i].J = _NumInputNodesDense[i];
  for (int i=0; i <_NumInputNodesSparseLength; ++i) this->SparseInputData[i].J = _NumInputNodesSparse[i];
  
  this->loss = loss;
  //this->regulariser = regulariser;
		
  this->nodes = std::vector<NeuralNetworkNodeGPUCpp*>(this->NumOutputNodes);		
  this->OutputNodes = nodes.data();

  //Initialise to nullptr\
  std::fill(this->nodes.begin(), this->nodes.end(), nullptr);
				
  //Since neural network has not been finalised, set finalised to false
  this->finalised = false;

}
					 
NeuralNetworkGPUCpp::~NeuralNetworkGPUCpp()  {};

void NeuralNetworkGPUCpp::init_hidden_node(NeuralNetworkNodeGPUCpp *_HiddenNode) {
	
  //Make sure that the neural network has not already been finalised!
  if (this->finalised) throw std::invalid_argument("Neural network has already been finalised!");

  if (_HiddenNode->NodeNumber >= this->NumHiddenNodes) {	

    std::int32_t NumAdditionalNodes = _HiddenNode->NodeNumber + 1 - this->NumHiddenNodes;

    //Extend hidden nodes vector
    std::vector<NeuralNetworkNodeGPUCpp*>::iterator it = this->nodes.begin() + this->nodes.size();
    this->nodes.insert(it, NumAdditionalNodes, nullptr);	

    //Increase NumHiddenNodes and reset pointer OutputNodes
    this->NumHiddenNodes += NumAdditionalNodes;
    this->OutputNodes = nodes.data() + this->NumHiddenNodes;

    //Increase NodeNumber of OutputNodes
    for (std::int32_t i=0; i<this->NumOutputNodes; ++i) if (this->OutputNodes[i] != nullptr) this->OutputNodes[i]->NodeNumber += NumAdditionalNodes;
  }

  this->nodes[_HiddenNode->NodeNumber] = _HiddenNode;
					
};

void NeuralNetworkGPUCpp::init_output_node(NeuralNetworkNodeGPUCpp *_OutputNode) {
		
  //Make sure that the neural network has not already been finalised!
  if (this->finalised) 
    throw std::invalid_argument("Neural network has already been finalised!");
  
  //Make sure that node number is in range
  if (_OutputNode->NodeNumber >= (std::int32_t)(this->nodes.size()) || _OutputNode->NodeNumber < 0) 
    throw std::invalid_argument("Output node: Node number out of range!");
				
  this->nodes[_OutputNode->NodeNumber] = _OutputNode;
						
};

void NeuralNetworkGPUCpp::finalise(/*MPI_Comm comm, std::int32_t rank, std::int32_t size,*/float _WeightInitRange) {

  //Make sure that neural net has not been finalised already
  if (this->finalised == true)
    throw std::invalid_argument("Neural network has already been finalised!");

  //Make sure that all nodes were initialised
  if (std::any_of(this->nodes.begin(), this->nodes.end(), [](NeuralNetworkNodeGPUCpp *node) {return node == nullptr;}))
      throw std::invalid_argument("Not all nodes have been initialised!");
    
  //Calculate pointer to hidden nodes fed into me
  for (auto node: this->nodes) {

    node->HiddenNodesFedIntoMePtr.clear();
    for (auto i: node->HiddenNodesFedIntoMe) node->HiddenNodesFedIntoMePtr.push_back(this->nodes[i]);

  }
   
  //Transfer number fo input nodes to nodes, so we can calculate the number of weights needed
  for (auto node: this->nodes) {

    //Set initial value to zero
    node->NumInputNodesCumulative = 0;

    //Add dense input
    for (auto dense: node->InputNodesFedIntoMeDense) node->NumInputNodesCumulative += this->DenseInputData[dense].J;

    //Add sparse input
    for (auto sparse: node->InputNodesFedIntoMeSparse) node->NumInputNodesCumulative += this->SparseInputData[sparse].J;
     
  }

  //Transfer number of output nodes to targets
  for (int i=0; i < this->NumOutputNodesDense; ++i) DenseTargets[i].J = 1;//Temporary solution until layers are implemented! 
  for (int i=0; i < this->NumOutputNodesSparse; ++i) SparseTargets[i].J = 1;//Temporary solution until layers are implemented! 

  //Calculate CumulativeNumWeightsRequired and initialise W
  std::int32_t lengthW = 0;
  std::vector<std::int32_t> CumulativeNumWeightsRequiredHost;
  for (auto node: this->nodes) {

    node->NeuralNet = this;
    CumulativeNumWeightsRequiredHost.push_back(lengthW);
    lengthW += node->get_num_weights_required();

  }

  CumulativeNumWeightsRequiredHost.push_back(lengthW);

  //Transfer CumulativeNumWeightsRequired to device vector
  this->CumulativeNumWeightsRequired = thrust::device_vector<std::int32_t>(CumulativeNumWeightsRequiredHost.data(), CumulativeNumWeightsRequiredHost.data() + CumulativeNumWeightsRequiredHost.size());

  //Init Whost
  std::vector<float> Whost(lengthW);
  
  std::mt19937 gen(1);//Note that we deliberately choose a constant seed to get the same output every time we call the function
  std::uniform_real_distribution<float> dist(_WeightInitRange*(-1.0f), _WeightInitRange);

  //Initialise weight vector
  //The vector of weights associated with the input nodes cannot be a csr_matrix. The solution is to keep a set of weights that always assume the value of 0.0.
  for (auto node: this->nodes) {
         
    for (std::int32_t i = CumulativeNumWeightsRequiredHost[node->NodeNumber]; i < CumulativeNumWeightsRequiredHost[node->NodeNumber + 1]; ++i) Whost[i] = dist(gen);
            
  }
  
  //Transfor to device vector
  this->W = thrust::device_vector<float>(Whost.data(), Whost.data() + Whost.size());

  //Set finalised to true so we know we can now fit the neural network
  this->finalised = true;
  
}

std::int32_t NeuralNetworkGPUCpp::get_length_params() {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");

  return (std::int32_t)(this->W.size());
		
};

void NeuralNetworkGPUCpp::get_params(float *_W, std::int32_t _LengthW) {

  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  
  for (std::int32_t i=0; i<_LengthW; ++i) _W[i] = this->W[i];

}

std::int32_t NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_dense_length(std::int32_t _NodeNumber) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_NodeNumber < 0 || _NodeNumber >= (std::int32_t)(nodes.size())) std::invalid_argument("NodeNumber out of bounds!");

  return (std::int32_t)(this->nodes[_NodeNumber]->InputNodesFedIntoMeDense.size());
		
};

void NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_dense(std::int32_t _NodeNumber, std::int32_t *_InputNodesFedIntoMeDense, std::int32_t _InputNodesFedIntoMeDenseLength) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_NodeNumber < 0 || _NodeNumber >= (std::int32_t)(nodes.size())) std::invalid_argument("NodeNumber out of bounds!");
		
  for (std::int32_t i=0; i<_InputNodesFedIntoMeDenseLength; ++i) _InputNodesFedIntoMeDense[i] = this->nodes[_NodeNumber]->InputNodesFedIntoMeDense[i];
  		
};

std::int32_t NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_sparse_length(std::int32_t _NodeNumber) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_NodeNumber < 0 || _NodeNumber >= (std::int32_t)(nodes.size())) std::invalid_argument("NodeNumber out of bounds!");

  return (std::int32_t)(this->nodes[_NodeNumber]->InputNodesFedIntoMeSparse.size());
		
};

void NeuralNetworkGPUCpp::get_input_nodes_fed_into_me_sparse(std::int32_t _NodeNumber, std::int32_t *_InputNodesFedIntoMeSparse, std::int32_t _InputNodesFedIntoMeSparseLength) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_NodeNumber < 0 || _NodeNumber >= (std::int32_t)(nodes.size())) std::invalid_argument("NodeNumber out of bounds!");
		
  for (std::int32_t i=0; i<_InputNodesFedIntoMeSparseLength; ++i) _InputNodesFedIntoMeSparse[i] = this->nodes[_NodeNumber]->InputNodesFedIntoMeSparse[i];
  		
};
     
std::int32_t NeuralNetworkGPUCpp::get_hidden_nodes_fed_into_me_length(std::int32_t _NodeNumber) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_NodeNumber < 0 || _NodeNumber >= (std::int32_t)(nodes.size())) std::invalid_argument("NodeNumber out of bounds!");

  return (std::int32_t)(this->nodes[_NodeNumber]->HiddenNodesFedIntoMe.size());
		
};

void NeuralNetworkGPUCpp::get_hidden_nodes_fed_into_me(std::int32_t _NodeNumber, std::int32_t *_HiddenNodesFedIntoMe, std::int32_t _LengthHiddenNodesFedIntoMe) {
		
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  if (_NodeNumber < 0 || _NodeNumber >= (std::int32_t)(nodes.size())) std::invalid_argument("NodeNumber out of bounds!");
		
  for (std::int32_t i=0; i<_LengthHiddenNodesFedIntoMe; ++i) _HiddenNodesFedIntoMe[i] = this->nodes[_NodeNumber]->HiddenNodesFedIntoMe[i];
  		
};

void NeuralNetworkGPUCpp::load_dense(DenseInputStruct &data, float *_X, std::int32_t _I, std::int32_t _J) {

  //Transfer _I and _J
  data.I = _I;
  data.J = _J;

  //Transfer X to GPU and set Xptr
  data.X = thrust::device_vector<float>(_X, _X + _I*_J);
  data.Xptr = thrust::raw_pointer_cast(data.X.data()); 

}

void NeuralNetworkGPUCpp::load_dense_data(std::int32_t _NumInputNode, float *_X, std::int32_t _I, std::int32_t _J) {

  if (_NumInputNode >= (std::int32_t)(this->DenseInputData.size()) || _NumInputNode < 0) throw std::invalid_argument("NumInputNode out of bounds!");
  if (_J != this->DenseInputData[_NumInputNode].J) throw std::invalid_argument("Width J of array provided does not match the width that has been set when initialising the network!");
  
  this->load_dense(this->DenseInputData[_NumInputNode], _X, _I, _J);

}

void NeuralNetworkGPUCpp::load_dense_targets(std::int32_t _NumOutputNode, float *_Y, std::int32_t _I, std::int32_t _J) {

  if (_NumOutputNode >= (std::int32_t)(this->DenseTargets.size()) || _NumOutputNode < 0) throw std::invalid_argument("NumOutputNode out of bounds!");
  if (_J != this->DenseTargets[_NumOutputNode].J) throw std::invalid_argument("Width J of array provided does not match the width that has been set when initialising the network!");
  
  this->load_dense(this->DenseTargets[_NumOutputNode], _Y, _I, _J);

}

void NeuralNetworkGPUCpp::load_sparse(SparseInputStruct &data, float *_XData, std::int32_t _XDataLength,  std::int32_t *_XIndices, std::int32_t _XIndicesLength, std::int32_t *_XIndptr, std::int32_t _XIndptrLength, std::int32_t _I, std::int32_t _J) {

  //Transfer _I and _J
  data.I = _I;
  data.J = _J;

  //Transfer XData to GPU and set XDataPtr  
  data.XData = thrust::device_vector<float>(_XData, _XData + _XDataLength);
  data.XDataPtr = thrust::raw_pointer_cast(data.XData.data()); 

  //Transfer XIndices to GPU and set XIndicesPtr
  data.XIndices = thrust::device_vector<std::int32_t>(_XIndices, _XIndices + _XIndicesLength);
  data.XIndicesPtr = thrust::raw_pointer_cast(data.XIndices.data()); 

  //Transfer XIndptr to GPU and set XIndptrPtr
  data.XIndptr = thrust::device_vector<std::int32_t>(_XIndptr, _XIndptr + _XIndptrLength);
  data.XIndptrPtr = thrust::raw_pointer_cast(data.XIndptr.data()); 

}

void NeuralNetworkGPUCpp::load_sparse_data(std::int32_t _NumInputNode, float *_XData, std::int32_t _XDataLength,  std::int32_t *_XIndices, std::int32_t _XIndicesLength, std::int32_t *_XIndptr, std::int32_t _XIndptrLength, std::int32_t _I, std::int32_t _J) {

  if (_NumInputNode >= (std::int32_t)(this->SparseInputData.size()) || _NumInputNode < 0) throw std::invalid_argument("NumInputNode out of bounds!");
  if (_J != this->SparseInputData[_NumInputNode].J) throw std::invalid_argument("Width J of array provided does not match the width that has been set when initialising the network!");

  this->load_sparse(this->SparseInputData[_NumInputNode], _XData, _XDataLength, _XIndices, _XIndicesLength, _XIndptr, _XIndptrLength, _I, _J);

}

void NeuralNetworkGPUCpp::load_sparse_targets(std::int32_t _NumOutputNode, float *_YData, std::int32_t _YDataLength,  std::int32_t *_YIndices, std::int32_t _YIndicesLength, std::int32_t *_YIndptr, std::int32_t _YIndptrLength, std::int32_t _I, std::int32_t _J) {

  if (_NumOutputNode >= (std::int32_t)(this->SparseTargets.size()) || _NumOutputNode < 0) throw std::invalid_argument("NumOutputNode out of bounds!");
  if (_J != this->SparseTargets[_NumOutputNode].J) throw std::invalid_argument("Width J of array provided does not match the width that has been set when initialising the network!");

  this->load_sparse(this->SparseTargets[_NumOutputNode], _YData, _YDataLength, _YIndices, _YIndicesLength, _YIndptr, _YIndptrLength, _I, _J);

}

void NeuralNetworkGPUCpp::delete_data() {

  for (auto data: this->DenseInputData) data.X.clear();

  for (auto data: this->DenseTargets) data.X.clear();

  for (auto data: this->SparseInputData) {
    data.XData.clear();
    data.XIndices.clear();
    data.XIndptr.clear();
  }

  for (auto data: this->SparseTargets) {
    data.XData.clear();
    data.XIndices.clear();
    data.XIndptr.clear();
  }

}
	           
void NeuralNetworkGPUCpp::transform(float *_Yhat, std::int32_t _IY2, std::int32_t _JY2, const std::int32_t _MinibatchSizeStandard, bool _sample, std::int32_t _SampleSize, bool _GetHiddenNodes) {
		
  //Make sure that neural network has been finalised!
  if (!this->finalised) throw std::invalid_argument("Neural network has not been finalised!");
  
  //Make sure that _IY2 matches I in input matrices
  for (auto data: this->DenseInputData) if (_IY2 != data.I) throw std::invalid_argument("All input matrices must have the exact same number of samples!");

  for (auto data: this->SparseInputData) if (_IY2 != data.I) throw std::invalid_argument("All input matrices must have the exact same number of samples!");
  
  //Store input values
  this->I = _IY2;
  this->sample = _sample;
  if (!_sample) _SampleSize = 1;

  const double SampleAvg = 1.0/((double)_SampleSize);

  //this->MinibatchSizeStandard determines the number of samples that are calculated at once when calling the functions.
  //It must be optimised for cache efficiency
  this->MinibatchSizeStandard = _MinibatchSizeStandard;

  //Set pointers contained in the NeuralNetworkNodes class
  for (std::size_t n=0; n<this->nodes.size(); ++n) this->nodes[n]->W = thrust::raw_pointer_cast(this->W.data()) + this->CumulativeNumWeightsRequired[n];
  
  //Init YhatTemp
  thrust::device_vector<float> YhatTemp(_Yhat, _Yhat + _IY2*_JY2);
  
  //Init cuBLAS handle
  cublasCreate(&(this->handle));

  //Calculate output
  std::int32_t MinibatchSize;
  for (std::int32_t MinibatchBegin=0; MinibatchBegin<this->I; MinibatchBegin += this->MinibatchSizeStandard) {

    //Calculate MinibatchSize
    MinibatchSize = std::min(this->I - MinibatchBegin, this->MinibatchSizeStandard);
    						
    //Calculate nodes
    for (auto node: this->nodes) node->calc_output(MinibatchBegin, MinibatchSize);

    //Add to YhatTemp
    for (std::int32_t n=0; n<this->NumOutputNodes; ++n) thrust::transform(this->OutputNodes[n]->output.begin(), this->OutputNodes[n]->output.end(), YhatTemp.begin() + _IY2*n + MinibatchBegin, YhatTemp.begin() + _IY2*n + MinibatchBegin, thrust::plus<float>());

  }	
  
  //Get data from YhatTemp and transpose
  for (std::int32_t i=0; i<_IY2; ++i) for (std::int32_t j=0; j<_JY2; ++j) _Yhat[i*_JY2 + j] = YhatTemp[j*_IY2 + i];

  //Destroy cuBLAS handle
  cublasDestroy(this->handle);
			
  //Clear data. so it does not unnecessarily take up space on the GPU
  this->delete_data();
		
};
