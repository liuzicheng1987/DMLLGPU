OptimiserCpp::OptimiserCpp(/*const std::int32_t _size, const std::int32_t _rank*/) {
		
    /*this->size = _size;
      this->rank = _rank;*/
		
}

OptimiserCpp::~OptimiserCpp() {}
	
//dev_function_type is defined in file OptimiserCpp.hpp
void OptimiserCpp::minimise (/*MPI_Comm _comm,*/NeuralNetworkGPUCpp *_neural_net, std::int32_t _num_samples, thrust::device_vector<float> &_W, std::int32_t _global_batch_size, const float _tol, const std::int32_t _max_num_epochs, std::vector<float> &_sum_gradients) {
	
  //Store all of the input values
  this->num_samples = _num_samples; 
  this->global_batch_size = _global_batch_size;

  //Set this->Wptr
  this->Wptr = thrust::raw_pointer_cast(_W.data());
				
  //Initialise dLdw and dLdwPtr
  this->dLdw = thrust::device_vector<float>(_W.size());
  this->dLdwPtr = thrust::raw_pointer_cast(this->dLdw.data());
  
  //Initialise SumdLdw
  this->SumdLdw = thrust::device_vector<float>(_W.size());	
		
  //Calculate the number of batches needed
  this->num_batches = _neural_net->calc_num_batches(_num_samples, _global_batch_size);

  std::cout << "_num_samples: " << _num_samples << "\n";
  std::cout << "_global_batch_size: " << _global_batch_size << "\n";

  std::cout << "this->num_batches: " << this->num_batches << "\n";
					
  //Create the threads and pass the values they need
  this->min(/*comm,*/_neural_net, _W, _tol, _max_num_epochs, _sum_gradients);

  //Clear this->dLdw and this->SumdLdw, so they don't take up space on the GPU
  this->dLdw.clear();
  this->SumdLdw.clear();
		
}
