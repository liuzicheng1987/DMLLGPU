ActivationFunctionCpp::ActivationFunctionCpp(
						   std::int32_t  _node_number, 
						   std::int32_t *_input_nodes_fed_into_me_dense, 
						   std::int32_t  _input_nodes_fed_into_me_dense_length, 
						   std::int32_t *_input_nodes_fed_into_me_sparse, 
						   std::int32_t  _input_nodes_fed_into_me_sparse_length, 
						   std::int32_t *_hidden_nodes_fed_into_me, 
						   std::int32_t  _hidden_nodes_fed_into_me_length, 
						   std::int32_t  _i_share_weights_with, 
						   bool          _no_weight_updates
						   ): NeuralNetworkNodeCpp (
									      _node_number,
									      _input_nodes_fed_into_me_dense, 
									      _input_nodes_fed_into_me_dense_length, 
									      _input_nodes_fed_into_me_sparse, 
									      _input_nodes_fed_into_me_sparse_length, 
									      _hidden_nodes_fed_into_me, 
									      _hidden_nodes_fed_into_me_length, 
									      _i_share_weights_with, 
									      _no_weight_updates
									      ) {

  //We are initialising these two vectors, so we can resize them later, if necessary
  this->output = thrust::device_vector<float>(1);
  this->delta = thrust::device_vector<float>(1);

}

ActivationFunctionCpp::~ActivationFunctionCpp() {};

std::int32_t ActivationFunctionCpp::get_num_weights_required() {

  //This is necessary for every class that inherits from NeuralNetworkNodeCpp
  return num_input_nodes_cumulative + static_cast<std::int32_t>(hidden_nodes_fed_into_me.size()) + 1; 

};

void ActivationFunctionCpp::calc_output(
					   const std::int32_t _batch_num, 
					   const std::int32_t _batch_size
					   ) {

  cublasStatus_t cstatus;//cuBLAS status variable - so we can check whether the cuBLAS operations were successful
  const float *w = this->W;//Pointer to weights
  
  std::int32_t dim;//Number of columns in input data - for convenience

  //Needed for cuBLAS transformations
  const float alpha = 1.0; 
  const float beta = 1.0; 

  //Resize output and delta, if necessary
  //Output is stored in the NeuralNetworkNodeCpp base class and stores the output of this node
  if (static_cast<std::int32_t>(this->output.size()) != _batch_size) {
    
    //Resize output
    this->output.resize(_batch_size);
    this->output_ptr = thrust::raw_pointer_cast(this->output.data());

    //Resize delta
    this->delta.resize(_batch_size);
    this->delta_ptr = thrust::raw_pointer_cast(this->delta.data());

  }

  //Initialise output to zero
  thrust::fill(
	       this->output.begin(), 
	       this->output.end(), 
	       0.0f
	       );

  //Transform dense input nodes
  for (std::int32_t i: this->input_nodes_fed_into_me_dense) {

    dim = this->NeuralNet->get_dense_input_data(i, _batch_num).dim;//For convenience

    //Linear transformation of input data using cuBLAS
    //output = alpha*Xw + beta*output 
    //http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemv
    cstatus = cublasSgemv(this->NeuralNet->get_dense_handle(), 
			  CUBLAS_OP_T, 
			  dim,
			  _batch_size,
			  &alpha, 
			  this->NeuralNet->get_dense_input_data(i, _batch_num).X_ptr, 
			  dim, 
			  w, 
			  1, 
			  &beta, 
			  this->output_ptr,
			  1);

    //Make sure that matrix multiplication succeeded and throw error if it didn't!
    if (cstatus != CUBLAS_STATUS_SUCCESS) throw std::invalid_argument("Something went wrong during cuBLAS operation on dense input data!");
      
    w += dim;//Increment w
    
  } 

  //Transform sparse input nodes
  for (std::int32_t i: this->input_nodes_fed_into_me_sparse) {

    dim = this->NeuralNet->get_sparse_input_data(i, _batch_num).dim;//For convenience
    
    //...to be implemented

    w += dim;//Increment w
    
  } 
  
  //Transform hidden nodes fed into me and apply activation function
  this->forward_propagation(
			    w, 
			    this->hidden_nodes_fed_into_me_ptr.data(), 
			    this->hidden_nodes_fed_into_me_ptr.size(), 
			    this->output
			    );

}

void ActivationFunctionCpp::calc_delta() {

  this->backpropagation(
			this->W + this->num_input_nodes_cumulative, 
			this->hidden_nodes_fed_into_me_ptr.data(), 
			this->hidden_nodes_fed_into_me_ptr.size(), 
			this->output, 
			this->delta
			);

}

void ActivationFunctionCpp::calc_dLdw(float *_dLdw, const std::int32_t _batch_num, const std::int32_t _batch_size) {

  //pointer _dLdw points to the beginning of the weights relevant for this node. This is achieved by the g(...) function.

  cublasStatus_t cstatus;//cuBLAS status variable - so we can check whether the cuBLAS operations were successful

  const float *w = this->W;//Pointer to weights
  float *dldw = _dLdw;//Pointer to derivatives

  std::int32_t dim;//Number of columns in input data - for convenience

  //Needed for cuBLAS transformations
  const float alpha = 1.0; 
  const float beta = 0.0; 

  //Calculate derivatives for dense input nodes
  for (std::int32_t i: this->input_nodes_fed_into_me_dense) {

    dim = this->NeuralNet->get_dense_input_data(i, _batch_num).dim;//For convenience

    //Linear transformation of input data using cuBLAS
    //dldw = alpha*X(this->delta_ptr) + beta*dldw 
    //http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemv
    cstatus = cublasSgemv(
			  this->NeuralNet->get_dense_handle(), 
			  CUBLAS_OP_N, 
			  dim, 
			  _batch_size, 
			  &alpha, 
			  this->NeuralNet->get_dense_input_data(i, _batch_num).X_ptr, 
			  dim, 
			  this->delta_ptr, 
			  1, 
			  &beta, 
			  dldw, 
			  1
			  );

    if (cstatus != CUBLAS_STATUS_SUCCESS) 
      throw std::runtime_error("Something went wrong during cuBLAS operation on input data while calculating derivatives!");

    w += dim;//Increment w
    dldw += dim;//Increment dldw
    
  } 

  //Calculate derivatives for sparse input nodes
  for (std::int32_t i: this->input_nodes_fed_into_me_sparse) {

    dim = this->NeuralNet->get_sparse_input_data(i, _batch_num).dim;//For convenience

    //...to be implemented

    w += dim;//Increment w
    dldw += dim;//Increment dldw
    
  }   

  //Calculate derivatives for hidden nodes fed into this node
  ActivationFunction::calc_dev_hidden(
				      dldw, 
				      this->hidden_nodes_fed_into_me_ptr.data(), 
				      this->hidden_nodes_fed_into_me_ptr.size(), 
				      this->delta
				      );
   
}
